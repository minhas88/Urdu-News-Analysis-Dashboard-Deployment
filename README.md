# ğŸ“° Urdu News Classification Dashboard

A streamlined ETL + ML + Dashboard pipeline for Urdu news classification. It scrapes Urdu-language news articles from Pakistani media, cleans the text using NLP (Stanza), classifies them using a logistic regression model with TF-IDF features, and visualizes results with an interactive Streamlit dashboard.

Deployed serverlessly on [Railway](https://railway.app/) using Nixpacks â€” no Docker needed.

---

## ğŸš€ Architecture Overview

```
Scraper (news) â”€â”€â–º Cleaner (Stanza) â”€â”€â–º Model (TF-IDF + LogisticRegression)
       â”‚
       â–¼
PostgreSQL DB
   â”œâ”€â”€ labeled_articles
   â”œâ”€â”€ cleaned_articles
   â””â”€â”€ predictions
       â–²
       â”‚
FastAPI (inference API) â—„â”€â”€ Streamlit (dashboard UI)
```

---

## ğŸ“¦ Tech Stack

| Component     | Technology             |
|---------------|------------------------|
| Scraping      | BeautifulSoup + Requests |
| NLP Preproc   | Stanza (Urdu) + Stopwords |
| Model         | TF-IDF + LogisticRegression |
| Serving       | FastAPI                 |
| Visualization | Streamlit + Plotly     |
| Storage       | PostgreSQL (managed by Railway) |
| Infra         | Railway + Nixpacks     |

---

## ğŸ› ï¸ Getting Started (Locally)

### 1. Clone the repo

```bash
git clone https://github.com/your-username/Urdu-News-Analysis-Dashboard-Deployment.git
cd Urdu-News-Analysis-Dashboard-Deployment
```

### 2. Set up Python environment and install dependencies

```bash
pip install -r requirements.txt
```

### 3. Set environment variables

Create a `.env` file with your Railway PostgreSQL credentials:

```env
POSTGRES_DB=railway
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password_here
POSTGRES_HOST=postgres.railway.internal
POSTGRES_PORT=5432
```

> ğŸš¨ Do **not** commit `.env` to GitHub.

---

## ğŸ”ƒ Pipeline Usage

```bash
# Step 1: Ensure PostgreSQL is running (Railway or local)
# Step 2: Run everything through the orchestration script
bash start.sh
```

`start.sh` performs:
- DB readiness check
- Web scraping from 4 news sites
- Urdu text cleaning
- Model training and evaluation
- Starts FastAPI on port 8000 and Streamlit on port 8080

---

## ğŸŒ Accessing Services (During Local Dev)

| Service    | URL                     |
|------------|--------------------------|
| FastAPI    | http://localhost:8000/inference |
| Streamlit  | http://localhost:8080    |

---

## ğŸ“ Folder Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py              # FastAPI app
â”‚   â”œâ”€â”€ cleaner.py          # Text preprocessing (stanza + stopwords)
â”‚   â”œâ”€â”€ scrapper.py         # Scrapes Urdu news articles
â”‚   â”œâ”€â”€ streamlit_app.py    # Streamlit dashboard
â”‚   â”œâ”€â”€ train_model.py      # ML pipeline (TF-IDF + LogisticRegression)
â”‚   â”œâ”€â”€ stopwords-ur.txt    # Urdu stopword list
â”‚   â””â”€â”€ wait-for-postgres.sh # DB readiness script
â”œâ”€â”€ postgres-init.sql       # Optional schema bootstrap
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ start.sh                # Run scraper â†’ clean â†’ train â†’ launch
â””â”€â”€ README.md
```

---

## ğŸ“œ License

MIT License â€“ Free for personal and commercial use.
